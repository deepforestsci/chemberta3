import subprocess
import torch

REQUIRED_WEIGHTS_LIST = ['tok_emb.weight',
 'blocks.layers.0.attention.query_projection.weight',
 'blocks.layers.0.attention.query_projection.bias',
 'blocks.layers.0.attention.key_projection.weight',
 'blocks.layers.0.attention.key_projection.bias',
 'blocks.layers.0.attention.value_projection.weight',
 'blocks.layers.0.attention.value_projection.bias',
 'blocks.layers.0.attention.inner_attention.feature_map.omega',
 'blocks.layers.0.attention.out_projection.weight',
 'blocks.layers.0.attention.out_projection.bias',
 'blocks.layers.0.norm1.weight',
 'blocks.layers.0.norm1.bias',
 'blocks.layers.0.linear1.weight',
 'blocks.layers.0.linear1.bias',
 'blocks.layers.0.linear2.weight',
 'blocks.layers.0.linear2.bias',
 'blocks.layers.0.norm2.weight',
 'blocks.layers.0.norm2.bias',
 'blocks.layers.1.attention.query_projection.weight',
 'blocks.layers.1.attention.query_projection.bias',
 'blocks.layers.1.attention.key_projection.weight',
 'blocks.layers.1.attention.key_projection.bias',
 'blocks.layers.1.attention.value_projection.weight',
 'blocks.layers.1.attention.value_projection.bias',
 'blocks.layers.1.attention.inner_attention.feature_map.omega',
 'blocks.layers.1.attention.out_projection.weight',
 'blocks.layers.1.attention.out_projection.bias',
 'blocks.layers.1.norm1.weight',
 'blocks.layers.1.norm1.bias',
 'blocks.layers.1.linear1.weight',
 'blocks.layers.1.linear1.bias',
 'blocks.layers.1.linear2.weight',
 'blocks.layers.1.linear2.bias',
 'blocks.layers.1.norm2.weight',
 'blocks.layers.1.norm2.bias',
 'blocks.layers.2.attention.query_projection.weight',
 'blocks.layers.2.attention.query_projection.bias',
 'blocks.layers.2.attention.key_projection.weight',
 'blocks.layers.2.attention.key_projection.bias',
 'blocks.layers.2.attention.value_projection.weight',
 'blocks.layers.2.attention.value_projection.bias',
 'blocks.layers.2.attention.inner_attention.feature_map.omega',
 'blocks.layers.2.attention.out_projection.weight',
 'blocks.layers.2.attention.out_projection.bias',
 'blocks.layers.2.norm1.weight',
 'blocks.layers.2.norm1.bias',
 'blocks.layers.2.linear1.weight',
 'blocks.layers.2.linear1.bias',
 'blocks.layers.2.linear2.weight',
 'blocks.layers.2.linear2.bias',
 'blocks.layers.2.norm2.weight',
 'blocks.layers.2.norm2.bias',
 'blocks.layers.3.attention.query_projection.weight',
 'blocks.layers.3.attention.query_projection.bias',
 'blocks.layers.3.attention.key_projection.weight',
 'blocks.layers.3.attention.key_projection.bias',
 'blocks.layers.3.attention.value_projection.weight',
 'blocks.layers.3.attention.value_projection.bias',
 'blocks.layers.3.attention.inner_attention.feature_map.omega',
 'blocks.layers.3.attention.out_projection.weight',
 'blocks.layers.3.attention.out_projection.bias',
 'blocks.layers.3.norm1.weight',
 'blocks.layers.3.norm1.bias',
 'blocks.layers.3.linear1.weight',
 'blocks.layers.3.linear1.bias',
 'blocks.layers.3.linear2.weight',
 'blocks.layers.3.linear2.bias',
 'blocks.layers.3.norm2.weight',
 'blocks.layers.3.norm2.bias',
 'blocks.layers.4.attention.query_projection.weight',
 'blocks.layers.4.attention.query_projection.bias',
 'blocks.layers.4.attention.key_projection.weight',
 'blocks.layers.4.attention.key_projection.bias',
 'blocks.layers.4.attention.value_projection.weight',
 'blocks.layers.4.attention.value_projection.bias',
 'blocks.layers.4.attention.inner_attention.feature_map.omega',
 'blocks.layers.4.attention.out_projection.weight',
 'blocks.layers.4.attention.out_projection.bias',
 'blocks.layers.4.norm1.weight',
 'blocks.layers.4.norm1.bias',
 'blocks.layers.4.linear1.weight',
 'blocks.layers.4.linear1.bias',
 'blocks.layers.4.linear2.weight',
 'blocks.layers.4.linear2.bias',
 'blocks.layers.4.norm2.weight',
 'blocks.layers.4.norm2.bias',
 'blocks.layers.5.attention.query_projection.weight',
 'blocks.layers.5.attention.query_projection.bias',
 'blocks.layers.5.attention.key_projection.weight',
 'blocks.layers.5.attention.key_projection.bias',
 'blocks.layers.5.attention.value_projection.weight',
 'blocks.layers.5.attention.value_projection.bias',
 'blocks.layers.5.attention.inner_attention.feature_map.omega',
 'blocks.layers.5.attention.out_projection.weight',
 'blocks.layers.5.attention.out_projection.bias',
 'blocks.layers.5.norm1.weight',
 'blocks.layers.5.norm1.bias',
 'blocks.layers.5.linear1.weight',
 'blocks.layers.5.linear1.bias',
 'blocks.layers.5.linear2.weight',
 'blocks.layers.5.linear2.bias',
 'blocks.layers.5.norm2.weight',
 'blocks.layers.5.norm2.bias',
 'blocks.layers.6.attention.query_projection.weight',
 'blocks.layers.6.attention.query_projection.bias',
 'blocks.layers.6.attention.key_projection.weight',
 'blocks.layers.6.attention.key_projection.bias',
 'blocks.layers.6.attention.value_projection.weight',
 'blocks.layers.6.attention.value_projection.bias',
 'blocks.layers.6.attention.inner_attention.feature_map.omega',
 'blocks.layers.6.attention.out_projection.weight',
 'blocks.layers.6.attention.out_projection.bias',
 'blocks.layers.6.norm1.weight',
 'blocks.layers.6.norm1.bias',
 'blocks.layers.6.linear1.weight',
 'blocks.layers.6.linear1.bias',
 'blocks.layers.6.linear2.weight',
 'blocks.layers.6.linear2.bias',
 'blocks.layers.6.norm2.weight',
 'blocks.layers.6.norm2.bias',
 'blocks.layers.7.attention.query_projection.weight',
 'blocks.layers.7.attention.query_projection.bias',
 'blocks.layers.7.attention.key_projection.weight',
 'blocks.layers.7.attention.key_projection.bias',
 'blocks.layers.7.attention.value_projection.weight',
 'blocks.layers.7.attention.value_projection.bias',
 'blocks.layers.7.attention.inner_attention.feature_map.omega',
 'blocks.layers.7.attention.out_projection.weight',
 'blocks.layers.7.attention.out_projection.bias',
 'blocks.layers.7.norm1.weight',
 'blocks.layers.7.norm1.bias',
 'blocks.layers.7.linear1.weight',
 'blocks.layers.7.linear1.bias',
 'blocks.layers.7.linear2.weight',
 'blocks.layers.7.linear2.bias',
 'blocks.layers.7.norm2.weight',
 'blocks.layers.7.norm2.bias',
 'blocks.layers.8.attention.query_projection.weight',
 'blocks.layers.8.attention.query_projection.bias',
 'blocks.layers.8.attention.key_projection.weight',
 'blocks.layers.8.attention.key_projection.bias',
 'blocks.layers.8.attention.value_projection.weight',
 'blocks.layers.8.attention.value_projection.bias',
 'blocks.layers.8.attention.inner_attention.feature_map.omega',
 'blocks.layers.8.attention.out_projection.weight',
 'blocks.layers.8.attention.out_projection.bias',
 'blocks.layers.8.norm1.weight',
 'blocks.layers.8.norm1.bias',
 'blocks.layers.8.linear1.weight',
 'blocks.layers.8.linear1.bias',
 'blocks.layers.8.linear2.weight',
 'blocks.layers.8.linear2.bias',
 'blocks.layers.8.norm2.weight',
 'blocks.layers.8.norm2.bias',
 'blocks.layers.9.attention.query_projection.weight',
 'blocks.layers.9.attention.query_projection.bias',
 'blocks.layers.9.attention.key_projection.weight',
 'blocks.layers.9.attention.key_projection.bias',
 'blocks.layers.9.attention.value_projection.weight',
 'blocks.layers.9.attention.value_projection.bias',
 'blocks.layers.9.attention.inner_attention.feature_map.omega',
 'blocks.layers.9.attention.out_projection.weight',
 'blocks.layers.9.attention.out_projection.bias',
 'blocks.layers.9.norm1.weight',
 'blocks.layers.9.norm1.bias',
 'blocks.layers.9.linear1.weight',
 'blocks.layers.9.linear1.bias',
 'blocks.layers.9.linear2.weight',
 'blocks.layers.9.linear2.bias',
 'blocks.layers.9.norm2.weight',
 'blocks.layers.9.norm2.bias',
 'blocks.layers.10.attention.query_projection.weight',
 'blocks.layers.10.attention.query_projection.bias',
 'blocks.layers.10.attention.key_projection.weight',
 'blocks.layers.10.attention.key_projection.bias',
 'blocks.layers.10.attention.value_projection.weight',
 'blocks.layers.10.attention.value_projection.bias',
 'blocks.layers.10.attention.inner_attention.feature_map.omega',
 'blocks.layers.10.attention.out_projection.weight',
 'blocks.layers.10.attention.out_projection.bias',
 'blocks.layers.10.norm1.weight',
 'blocks.layers.10.norm1.bias',
 'blocks.layers.10.linear1.weight',
 'blocks.layers.10.linear1.bias',
 'blocks.layers.10.linear2.weight',
 'blocks.layers.10.linear2.bias',
 'blocks.layers.10.norm2.weight',
 'blocks.layers.10.norm2.bias',
 'blocks.layers.11.attention.query_projection.weight',
 'blocks.layers.11.attention.query_projection.bias',
 'blocks.layers.11.attention.key_projection.weight',
 'blocks.layers.11.attention.key_projection.bias',
 'blocks.layers.11.attention.value_projection.weight',
 'blocks.layers.11.attention.value_projection.bias',
 'blocks.layers.11.attention.inner_attention.feature_map.omega',
 'blocks.layers.11.attention.out_projection.weight',
 'blocks.layers.11.attention.out_projection.bias',
 'blocks.layers.11.norm1.weight',
 'blocks.layers.11.norm1.bias',
 'blocks.layers.11.linear1.weight',
 'blocks.layers.11.linear1.bias',
 'blocks.layers.11.linear2.weight',
 'blocks.layers.11.linear2.bias',
 'blocks.layers.11.norm2.weight',
 'blocks.layers.11.norm2.bias',
 'blocks.norm.weight',
 'blocks.norm.bias',
 'lang_model.embed.weight',
 'lang_model.embed.bias',
 'lang_model.ln_f.weight',
 'lang_model.ln_f.bias',
 'lang_model.head.weight']

def test_checkpoint_conversion():
    pytorch_checkpoint_path = '' # Add the path to downloaded molfromer deepchem checkpoint
    result = subprocess.run(
        [
            "python3", ".././molformer_finetune/convert_molformer_pytorch_ckpt_to_lightning.py",
            "--pytorch_checkpoint_path", pytorch_checkpoint_path,
            "--lightning_checkpoint_path", "molformer-lightning-10M.pt"
        ],
        capture_output=True,
        text=True
    )

    # Check if the script ran successfully
    assert result.returncode == 0, f"Script failed with error: {result.stderr}"
    data = torch.load("molformer-lightning-10M.pt")
    assert list(data['state_dict'].keys()) == REQUIRED_WEIGHTS_LIST
